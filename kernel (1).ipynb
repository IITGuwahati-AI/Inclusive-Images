{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport requests \nimport matplotlib.image as mpimg\nfrom sklearn import preprocessing\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['classes-trainable.csv', 'train_human_labels.csv', 'stage_1_sample_submission.csv', 'stage_1_test_images', 'tuning_labels.csv', 'stage_1_attributions.csv', 'train_bounding_boxes.csv', 'class-descriptions.csv', 'train_machine_labels.csv']\n['config', 'working', 'lib', 'input']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b23e09dcbb1b01a06a73e50e6f148f52621be54"
      },
      "cell_type": "code",
      "source": "#getting trainable classes from left file and getting label description for those classes only\ncl=pd.merge(pd.read_csv('../input/classes-trainable.csv'),\n            pd.read_csv('../input/classes-trainable.csv'),\n           how='left', on=['label_code'])\n\n#Stacks up both table. train_labels will contain 4 rows (ImageID,Source,LabelName,Confidence) for both sources human and machine.\ntrain_labels = pd.concat((pd.read_csv('../input/train_machine_labels.csv'), \n                          pd.read_csv('../input/train_human_labels.csv')), \n                         axis=0, ignore_index=True)\n\ntrain_bb = pd.read_csv('../input/train_bounding_boxes.csv')\ntrain_tl = pd.read_csv('../input/tuning_labels.csv')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a2c19ab4fda1f955fc540bbd2d6bb801853b5db"
      },
      "cell_type": "code",
      "source": "train_bb.set_index('ImageID',inplace=True)\ntrain_bb.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "                  Source  LabelName    ...     IsDepiction  IsInside\nImageID                                ...                          \n000002b66c9c498e  xclick  /m/01g317    ...               0         0\n000002b66c9c498e  xclick  /m/01g317    ...               0         0\n000002b66c9c498e  xclick  /m/01g317    ...               0         0\n000002b66c9c498e  xclick  /m/01g317    ...               0         0\n000002b66c9c498e  xclick  /m/01g317    ...               0         0\n\n[5 rows x 12 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>LabelName</th>\n      <th>Confidence</th>\n      <th>XMin</th>\n      <th>XMax</th>\n      <th>YMin</th>\n      <th>YMax</th>\n      <th>IsOccluded</th>\n      <th>IsTruncated</th>\n      <th>IsGroupOf</th>\n      <th>IsDepiction</th>\n      <th>IsInside</th>\n    </tr>\n    <tr>\n      <th>ImageID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000002b66c9c498e</th>\n      <td>xclick</td>\n      <td>/m/01g317</td>\n      <td>1</td>\n      <td>0.012500</td>\n      <td>0.195312</td>\n      <td>0.148438</td>\n      <td>0.587500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000002b66c9c498e</th>\n      <td>xclick</td>\n      <td>/m/01g317</td>\n      <td>1</td>\n      <td>0.025000</td>\n      <td>0.276563</td>\n      <td>0.714063</td>\n      <td>0.948438</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000002b66c9c498e</th>\n      <td>xclick</td>\n      <td>/m/01g317</td>\n      <td>1</td>\n      <td>0.151562</td>\n      <td>0.310937</td>\n      <td>0.198437</td>\n      <td>0.590625</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000002b66c9c498e</th>\n      <td>xclick</td>\n      <td>/m/01g317</td>\n      <td>1</td>\n      <td>0.256250</td>\n      <td>0.429688</td>\n      <td>0.651563</td>\n      <td>0.925000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000002b66c9c498e</th>\n      <td>xclick</td>\n      <td>/m/01g317</td>\n      <td>1</td>\n      <td>0.257812</td>\n      <td>0.346875</td>\n      <td>0.235938</td>\n      <td>0.385938</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8cab6ee2931ecd512b5e4807e5186d11704ce31"
      },
      "cell_type": "code",
      "source": "test = pd.read_csv('../input/stage_1_sample_submission.csv')\ntest = pd.merge(test, pd.read_csv('../input/stage_1_attributions.csv'), how='left', on=['image_id'])\ntest.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d4f9af97f5eb6e216c1842f016d7270289285e2"
      },
      "cell_type": "code",
      "source": "test['path'] = test['image_id'].map(lambda x: '../input/stage_1_test_images/' + str(x) + '.jpg')\ntest.head() #test now contains also path for their respective image_id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import bq_helper\nfrom bq_helper import BigQueryHelper\n\nopen_images = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\", \n                                       dataset_name=\"open_images\")\nopen_images.list_tables()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "['annotations_bbox', 'dict', 'images', 'labels']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c28f279b4134e440cc621f30597955ab5a18882"
      },
      "cell_type": "code",
      "source": "# getting URL from open_images dataset for image_id in train_labels \nimage_ids = train_labels.ImageID.unique()\n\nfor i in range(0, len(image_ids), 20):\n    open_images = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\", dataset_name=\"open_images\")\n    query = \"SELECT image_id, thumbnail_300k_url, original_url, original_landing_url  FROM `bigquery-public-data.open_images.images` WHERE image_id IN ('\" + \"', '\".join(image_ids[i : i+1000]) + \"');\"\n    df = open_images.query_to_pandas_safe(query, max_gb_scanned=10)\n    df.to_csv('image_urls' + str(i).zfill(10) + '.csv')\n    break",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca34c24ba5d9e79b51a631d39a81d77117b204c8"
      },
      "cell_type": "code",
      "source": "print(df.shape) \nurls=df.values\ndf.head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(1000, 4)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "           image_id                        ...                                                       original_landing_url\n0  0003bf6ad3a94983                        ...                          https://www.flickr.com/photos/lum1neuz/4222511969\n1  0005bda112291d3b                        ...                          https://www.flickr.com/photos/derricksphotos/5...\n2  00030b8c7652041d                        ...                           https://www.flickr.com/photos/veritatem/18460961\n3  00081db9138ff646                        ...                              https://www.flickr.com/photos/snapr/565353386\n4  00050546c36b308c                        ...                          https://www.flickr.com/photos/anne-cathrine_ny...\n\n[5 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>thumbnail_300k_url</th>\n      <th>original_url</th>\n      <th>original_landing_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0003bf6ad3a94983</td>\n      <td>None</td>\n      <td>https://farm4.staticflickr.com/4033/4222511969...</td>\n      <td>https://www.flickr.com/photos/lum1neuz/4222511969</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0005bda112291d3b</td>\n      <td>None</td>\n      <td>https://c4.staticflickr.com/1/252/521666000_43...</td>\n      <td>https://www.flickr.com/photos/derricksphotos/5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00030b8c7652041d</td>\n      <td>None</td>\n      <td>https://c6.staticflickr.com/1/13/18460961_6b60...</td>\n      <td>https://www.flickr.com/photos/veritatem/18460961</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00081db9138ff646</td>\n      <td>None</td>\n      <td>https://farm7.staticflickr.com/1064/565353386_...</td>\n      <td>https://www.flickr.com/photos/snapr/565353386</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00050546c36b308c</td>\n      <td>None</td>\n      <td>https://c5.staticflickr.com/5/4022/4499952655_...</td>\n      <td>https://www.flickr.com/photos/anne-cathrine_ny...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5652666dd3e81614bf15a571c916ac4236b1cc44"
      },
      "cell_type": "code",
      "source": "num_pictures=128\nimage_size=64\nnum_channels=3\n",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3742cca5621c31c0d9b093794d4bee22a70a730d"
      },
      "cell_type": "code",
      "source": "\ndef get_data_from_url(image_id,url,image_index,image_data,labels):\n    r = requests.get(url)\n    with open(\"img.jpg\",'wb') as f: \n        f.write(r.content) \n        \n        file_data=mpimg.imread(\"../working/img.jpg\")\n        \n        \n        bb=train_bb.loc[image_id,['YMin','XMin','YMax','XMax']].values\n        if len(bb.shape)==1:\n            box=np.ndarray(shape=(1,4))\n            box[0,:]=bb[0]\n            bb=box\n        lb=train_bb.loc[image_id,['LabelName']]\n        label_gate=0\n        if(lb.shape[0]==1):\n            lb=lb.values\n            gate=1\n        else:\n            lb=lb['LabelName'].tolist()\n        \n        y=np.ndarray(shape=(1,file_data.shape[0],file_data.shape[1],3))\n        y[0,:,:,:]=file_data[:,:,0:3]\n        \n        cropped=tf.image.crop_and_resize(image=y,boxes=bb,box_ind=[0]*bb.shape[0],crop_size=[image_size,image_size],method='bilinear')\n        sess=tf.Session()\n        with sess.as_default():\n            tensor=cropped\n            cropped=tensor.eval()\n        n=cropped.shape[0]\n        for i in range(n):\n            image_data[image_index,:,:,:]=cropped[i,:,:,:]\n            image_index=image_index+1\n            if label_gate==0:\n                labels.append(lb[i])\n            else:\n                labels.extend(lb)\n            if image_index%50==0:\n                print(image_index)\n            if image_index>=num_pictures:\n                break\n        \n        f.close()\n        os.remove(\"../working/img.jpg\")\n        return image_index,image_data,labels",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5d049aa00b624d1f9d2fe14b78d1053ae5c0a5b"
      },
      "cell_type": "code",
      "source": "def get_next_batch(url_index):\n    image_index=0\n    image_data=np.ndarray(shape=(num_pictures,image_size,image_size,num_channels))\n    labels=[]\n    k=url_index\n    for i in range(k,k+num_pictures):\n        image_id=urls[i,0]\n        url=urls[i,2]\n        image_index,image_data,labels=get_data_from_url(image_id,url,image_index,image_data,labels)\n        url_index=url_index+1\n        if image_index>=num_pictures:\n            break\n    \n    \n    labels=np.asarray(labels)\n    \n\n    random=np.arange(num_pictures)\n    np.random.shuffle(random)\n    image_data=image_data[random]\n    labels=labels[random]\n    \n    \n    return image_data,labels,url_index",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d062e60ade9bee6be9caff0b261a69a11142a5f"
      },
      "cell_type": "code",
      "source": "all_labels=train_bb['LabelName'].values.tolist()\nle = preprocessing.LabelEncoder()\ntraining_le = le.fit(all_labels)\nnum_classes=le.classes_.shape[0]",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd10e38f1ed9e89319df9144e8235e4ec7a8d34d"
      },
      "cell_type": "code",
      "source": "def get_encoded_labels(labels):\n    training_labels_encoded = training_le.transform(labels)\n    return training_labels_encoded",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e972cb31c80a9165b49a73742c7172336b8904db"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8fc98be2365dc78a67499bce8e2b2e080d0fd652"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ff1dd80da772243e2ea210376e5e093bce915dc"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9991d0c1dbd38ee0e6576e59e51488a1ef2f55b5"
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Add, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Concatenate\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f61511e0f4b6dad0bb93e74d1712d76d14660e32"
      },
      "cell_type": "code",
      "source": "def identity_block(X, f, filters):\n    \n    F1, F2, F3 = filters\n     \n    X_shortcut = X\n   \n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same',kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n\n    X = X = Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid',kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n\n    X = layers.Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ff8f91e663ac29c4fa2359102c1792a73910090"
      },
      "cell_type": "code",
      "source": "\ndef convolutional_block(X, f, filters,s = 2):\n    \n    F1, F2, F3 = filters\n    \n    X_shortcut = X\n\n    X = Conv2D(F1, (1, 1), strides = (s,s), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(F2,(f,f),strides=(1,1),padding='same',kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(F3,(1,1),strides=(1,1),padding='valid',kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n\n    X_shortcut = Conv2D(F3,(1,1),strides=(s,s),padding='valid',kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n\n    X = layers.Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    return X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8e755266aa50d03fecb4c01a5b779181d64a957"
      },
      "cell_type": "code",
      "source": "\ndef ResNet50(input_shape, classes):\n    \n    X_input = Input(input_shape)\n\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n    X = identity_block(X, 3, [64, 64, 256])\n    X = identity_block(X, 3, [64, 64, 256])\n\n    X = convolutional_block(X,f=3,filters=[128,128,512],s=2)\n    X = identity_block(X,3,[128,128,512])\n    X = identity_block(X,3,[128,128,512])\n    X = identity_block(X,3,[128,128,512])\n\n    X = convolutional_block(X,f=3,filters=[256,256,1024],s=2)\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n\n    X = convolutional_block(X,f=3,filters=[512,512,2048],s=2)\n    X = identity_block(X,3,[512,512,2048])\n    X = identity_block(X,3,[512,512,2048])\n\n    X = AveragePooling2D((2,2))(X)\n    \n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    model = Model(inputs = X_input, outputs = X)\n\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9770b4490e19dc9dfc067041fac8d7789b65c1c6"
      },
      "cell_type": "code",
      "source": "model = ResNet50(input_shape = (image_size, image_size, 3), classes=num_classes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0fd47a03f0799e8cbf410bc178f9a484807b082"
      },
      "cell_type": "code",
      "source": "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4133a2265bb231b37b607f479a9a544aadb51e6f"
      },
      "cell_type": "code",
      "source": "url_index=0\ntimes=150\nfor i in range(0,times):\n    print(url_index)\n    image_data,labels,url_index=get_next_batch(url_index)\n    Y=get_encoded_labels(labels)\n    model.fit(image_data, Y, epochs = 3, batch_size = 32)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec592a250f599f41525d8599e431f93fea4a814d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}